input {
     beats {
          port => xx
          host => ["xx"]
     }
}

filter {
    # Log received from filebeat input
    if [mode] == "delivery" {
        grok {
            patterns_dir   => "C:\Logstash\config\patterns.d"
            match => { "message" => "%{SM_TIME:Time} \[%{SM_ID:ID}] %{SM_CM}: %{GREEDYDATA:Extra}|%{SM_TIME:Time} \[%{SM_ID:ID}] %{GREEDYDATA:Extra}" }
        }
        # Log received from extra input
        grok {
            patterns_dir   => "C:\Logstash\config\patterns.d"
            match          => [ "message", "%{SM_PROCESS_DELIVERY_STATUS}" ]
            tag_on_failure => [ "_grok_sm_process_nomatch" ]
            add_tag        => [ "DELIVERY" ]
        }

        grok {
            patterns_dir   => "C:\Logstash\config\patterns.d"
            match          => [ "message", "%{SM_DELIVERED}" ]
            tag_on_failure => [ "_grok_sm_delivery_nomatch" ]
            add_tag        => [ "DELIVERY" ]
        }

        grok {
            patterns_dir   => "C:\Logstash\config\patterns.d"
            match          => [ "message", "%{SM_CONNECTION}" ]
            tag_on_failure => [ "_grok_sm_connection_nomatch" ]
            Add_tag        => [ "DELIVERY" ]
        }

        grok {
            patterns_dir   => "C:\Logstash\config\patterns.d"
            match          => [ "message", "%{SM_PMG}" ]
            tag_on_failure => [ "_grok_sm_pmg_nomatch" ]
            add_tag        => [ "DELIVERY" ]
        }

        grok {
            patterns_dir   => "C:\Logstash\config\patterns.d"
            match          => [ "message", "%{SM_MSID}" ]
            tag_on_failure => [ "_grok_sm_msid_nomatch" ]
            add_tag        => [ "DELIVERY" ]
        }

        grok {
            patterns_dir   => "C:\Logstash\config\patterns.d"
            match          => [ "message", "%{SM_BOUNCED}" ]
            tag_on_failure => [ "_grok_sm_bounced_nomatch" ]
            add_tag        => [ "DELIVERY" ]
        }
    }

    # Do some data type conversions
    mutate {
        rename => [
            "[agent][hostname]", "Host",
            "domain_from", "Domain From",
            "domain_to", "Domain To",
            "sm_remote_ip", "Remote IP",
            "sm_remote_port", "Remote Port",
            "sm_client_ip", "Client IP",
            "sm_client_port", "Client Port",
            "sm_messageid", "Message ID"
        ]
        convert => [
            "Remote Port", "integer",
            "Client Port", "integer"
        ]
        remove_field => [
            "[agent][ephemeral_id]", "[agent][name]", "[agent][id]", "[agent][type]", "[agent][version]", "domain", "dsn", "ecs", "mode", "host", "message", "input", "log", "offset"
        ]
    }

    geoip {
        source      => "Remote IP"
        target      => "geoip"
        database    => "C:\Logstash\config\GeoLite2-City.mmdb"
        add_field   => [ "[location]", "%{[geoip][longitude]}" ]
        add_field   => [ "[location]", "%{[geoip][latitude]}" ]
    }

    mutate {
        remove_field => [
            "[geoip][real_region_name]",
            "[geoip][continent_code]",
            "[geoip][area_code]",
            "[geoip][dma_code]",
            "[geoip][ip]",
            "[geoip][country_code2]",
            "[geoip][country_code3]",
            "[geoip][latitude]",
            "[geoip][location.lat]",
            "[geoip][location.lon]",
            "[geoip][longitude]",
            "[geoip][timezone]",
            "[geoip][postal_code]",
            "[geoip][region_code]",
            "[geoip][region_name]",
            "[geoip][city_name]",
            "[geoip][location]",
            "location"
        ]
        rename => [
            "[geoip][country_name]", "Country"
        ]
        remove_tag => [
            "_grokparsefailure", "_grok_sm_process_nomatch", "_grok_sm_delivery_nomatch", "_grok_sm_connection_nomatch", "_grok_sm_pmg_nomatch", "_grok_sm_msid_nomatch", "_grok_sm_bounced_nomatch", "_geoip_lookup_failure", "beats_input_codec_plain_applied"
        ]
    }
}

output {
    elasticsearch {
        hosts => [
            "https://cluster-elasticsearch"
        ]
        api_key => "xx"
        cacert => 'C:\Logstash\ca\ca.crt'
        ssl => 'true'
        ssl_certificate_verification => 'true'
        manage_template => false
        index => "xx-xx-delivery-xx-%{+MM.YYYY}"
    }
    stdout { codec => rubydebug }
}